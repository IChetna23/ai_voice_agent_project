# ai_voice_agent_project
Voice AI Agent for Telephonic screening of Candidates - This is an automated calling agent that is capable of asking general screening questions like: Basic Introduction, Skillset, experience, etc. The agent transcribes, analyzes, reasons, and screens-in the candidates based on their responses

âœ¨ Features
ğŸ¤ Voice-based HR Questioning using gTTS and pygame

ğŸ”Š Candidate Response Playback via pre-recorded .wav files

ğŸ§  Automatic Transcription using OpenAI Whisper

ğŸ§ª NLP Pipeline for:

Sentiment Analysis

Keyword Extraction

WH-Question Detection

âš™ï¸ Rule-Based Reasoning Engine (agent_logic.py) to:

Flag candidates

Prompt for more information

Auto-respond to candidate queries

Final recommendation based on sentiment, content, and question handling

ğŸ—‚ï¸ Folder Structure
graphql
Copy
Edit
project-root/
â”œâ”€â”€ stimulate_call.py        # Main simulation logic
â”œâ”€â”€ agent_logic.py           # Rule-based reasoning
â”œâ”€â”€ nlp_pipeline.py          # NLP pipeline using spaCy/textblob/etc.
â”œâ”€â”€ sample_audio/            # Contains folders: candidate1, candidate2, candidate3
â”‚   â”œâ”€â”€ candidate1/
â”‚   â”‚   â”œâ”€â”€ a1.wav
â”‚   â”‚   â”œâ”€â”€ a2.wav
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ candidate2/
â”‚       â””â”€â”€ ...
â””â”€â”€ README.md                # This file
ğŸ› ï¸ How It Works
The HR Agent speaks predefined questions one by one.

The candidate's voice reply (pre-recorded .wav) is played.

Whisper AI transcribes the audio to text.

The NLP pipeline analyzes the transcript:

Extracts tone and key information

Detects WH-questions asked by the candidate

Agent logic evaluates:

Whether to flag, prompt, or proceed

Auto-responses are triggered for candidate questions like:

â€œWhat tech stack do you use?â€

â€œIs this a remote role?â€

ğŸ—£ï¸ Sample Questions Asked
Please introduce yourself.

What is your experience and skill set?

Where are you currently located?

Are you willing to join immediately?

Do you have any questions for us?

â–¶ï¸ Run the Simulation (stimulate_call.py)
1. Install Requirements
bash
Copy
Edit
pip install pygame gTTS openai-whisper pyttsx3
2. Run the Agent
bash
Copy
Edit
python stimulate_call.py
Then enter:

bash
Copy
Edit
Enter candidate number (e.g., 1, 2, 3): 1
ğŸ§ Make sure candidate audio files exist in sample_audio/candidate1/ as a1.wav, a2.wav, etc.

ğŸ§° Technologies Used
Python

Whisper by OpenAI (for transcription)

Hugging Face Transformers (for NLP tasks - Sentiment Analysis and NER)

gTTS + Pygame (for Text-to-Speech and audio)

Custom Rule-Based Logic
